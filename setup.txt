
Things that need to be changed so that the input works without the mysql thing, or with it.



Add methods to tm.jar that generate the sqlite table from an input csv.
Add methods to tm.jar that 















Python script for running the whole pipeline from the command line (without the ML experiment part).
1 make call to jar to generate mysql database from an input csv.
2 (optional) make calls to annotate the data with ncbo annotator.
3 make calls to annotate the data with noble coder.
4 organize all those temporary files where they can be retrieved.
5 make call to jar to generate the ouput csv file from all those term probabilities.
6 should know whether or not this is tagged data to include comparison columns or not.


Things that should be included as options.
1 Configuration file that has the options for the noble coder run.
2 Configuration file that has the options for the ncbo annotator run.
3 File that contains a table of the dG probabilities estimated from data.
4 File that contains any other information about the configuration options
	-which ontologies to use
	-which evaluation metrics to include in the output file
	-rules for default terms to use for different EQ components.
	-numerical values for different confidence values from the annotation tools.



R scripts that can be run to produce plots for the tagged data.

Text files containing information on how to run the pipeline for new data.




Define what is necessary for the path dir before running
	ontology files
	text data files
	jar file
	python scripts
	

















